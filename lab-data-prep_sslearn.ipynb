{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asr/tensorflow-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/asr/tensorflow-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPORA: Specific vs Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_cal_1: 99412, Corpus_cal_2: 266442, Corpus_2: 10111563, Ratio: 0.036\n",
      "CPU times: user 3.97 s, sys: 1.44 s, total: 5.41 s\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE: Put in corpus_2 the largest corpus\n",
    "\n",
    "num_lines_corpus_spec_1  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/calendar/jsgf/jsgf-calendar-1'))\n",
    "num_lines_corpus_spec_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/calendar/subtitles/subtitle-cleaned-keyfiltered'))\n",
    "#num_lines_corpus_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/generic/paisa-cleaned-v8-0'))\n",
    "num_lines_corpus_gen_2  = sum(1 for line in open('/home/asr/Data/classif_task/dev_data/generic-maxlength16/generic-corpus-maxlength16-v1'))\n",
    "\n",
    "ratio_cal = num_lines_corpus_spec_1 / float(num_lines_corpus_spec_2)\n",
    "ratio = (num_lines_corpus_spec_1 + num_lines_corpus_spec_2) / float(num_lines_corpus_gen_2) #if num_lines_corpus_1 < num_lines_corpus_1 else num_lines_corpus_2 / float(num_lines_corpus_1)\n",
    "print('Corpus_cal_1: %d, Corpus_cal_2: %d, Corpus_2: %d, Ratio: %0.3f' %(num_lines_corpus_spec_1, num_lines_corpus_spec_2, num_lines_corpus_gen_2, ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37310934462284473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_cal = num_lines_corpus_spec_1 / float(num_lines_corpus_spec_2)\n",
    "ratio_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Data-Frame (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (num_lines_corpus_spec_1 + ratio_cal*num_lines_corpus_spec_2) / float(num_lines_corpus_gen_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory_1, directory_2, directory_3):\n",
    "    # NOTE: Put in directory_2 the largest corpus\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"class\"] = []\n",
    "    l1 = 0\n",
    "    for file_path in os.listdir(directory_1):\n",
    "        with tf.gfile.GFile(os.path.join(directory_1 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines()]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(int(1))\n",
    "    \n",
    "    for file_path in os.listdir(directory_2):\n",
    "        with tf.gfile.GFile(os.path.join(directory_2 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines() if np.random.random() <= ratio_cal]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(int(1))\n",
    "    \n",
    "    for file_path in os.listdir(directory_3):\n",
    "        with tf.gfile.GFile(os.path.join(directory_3, file_path), \"rb\") as f:\n",
    "            # Balancing the dataset\n",
    "            list_of_sentences = [s.strip().decode() for s in f.readlines() if np.random.random() <= ratio]\n",
    "            for i in range(len(list_of_sentences)):\n",
    "                data[\"sentence\"].append(list_of_sentences[i])\n",
    "                data[\"class\"].append(int(0))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 2.53 s, total: 36.7 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directory_1 = '/home/asr/Data/classif_task/dev_data/calendar/jsgf/'\n",
    "directory_2 = '/home/asr/Data/classif_task/dev_data/calendar/subtitles/'\n",
    "directory_3 = '/home/asr/Data/classif_task/dev_data/generic-maxlength16/'\n",
    "\n",
    "#directory_1 = '/home/asr/Data/classif_task/jsgf_data/email/'\n",
    "#directory_2 = '/home/asr/Data/classif_task/jsgf_data/reminder/'\n",
    "\n",
    "dataset_df = load_dataset(directory_1, directory_2, directory_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence\n",
       "class          \n",
       "0        199457\n",
       "1        198734"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Balanced\n",
    "dataset_df.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modifica attività\n",
      "ma è anche come mille biscioni insaponati che non sai dove finisce uno e dove comincia\n",
      "fai partire calendario\n",
      "ma è anche certo che quei personaggi non servono né a scamarcio né alla chiatti per\n",
      "mostrami la vista giorno nel calendario\n",
      "ma è anche abbastanza normale che lincumbent faccia valere il proprio peso di mercato gli asset\n",
      "vorrei aprire calendario e visualizza settimana\n",
      "ma è altrettanto importante ricordare in mazzoni l'uso e la conoscenza degli elementi classici e delle\n",
      "mostra applicazione agenda per favore e visualizza settimana\n",
      "ma è altresì necessario non limitarsi alla difesa nei processi connotata da difficoltà tuttaltro che lievi\n",
      "vorrei vedere la vista giorno nell'applicazione calendario per piacere\n",
      "ma è altresì dimostrata la sua azione di desistenza rispetto al genocidio nei confronti delle locali\n",
      "puoi aprire vista settimana nell'app calendario per favore ?\n",
      "cantata dal bassista curt smith\n",
      "imposta notifiche nelle impostazioni dell'agenda\n",
      "a scoprire nei tripodi nuovi ed emozionanti aspetti a volte è bene lanciarsi in territori inesplorati\n",
      "vorrei vedere visualizzazione giorno nell'app calendario per piacere\n",
      "henri bergson e addirittura albert einstein\n",
      "puoi mostrare la vista anno nell'agenda per piacere ?\n",
      "ma durante le lotte tra le fazioni guglielmo divenne fuoruscito\n"
     ]
    }
   ],
   "source": [
    "# Print some samples\n",
    "for i in range(10):\n",
    "    print(dataset_df.iloc[i]['sentence'])\n",
    "    print(dataset_df.iloc[-i -1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modifica attività</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fai partire calendario</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostrami la vista giorno nel calendario</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vorrei aprire calendario e visualizza settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mostra applicazione agenda per favore e visual...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0                                  modifica attività      1\n",
       "1                             fai partire calendario      1\n",
       "2            mostrami la vista giorno nel calendario      1\n",
       "3    vorrei aprire calendario e visualizza settimana      1\n",
       "4  mostra applicazione agenda per favore e visual...      1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398186</th>\n",
       "      <td>ma è altresì necessario non limitarsi alla dif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398187</th>\n",
       "      <td>ma è altrettanto importante ricordare in mazzo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398188</th>\n",
       "      <td>ma è anche abbastanza normale che lincumbent f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398189</th>\n",
       "      <td>ma è anche certo che quei personaggi non servo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398190</th>\n",
       "      <td>ma è anche come mille biscioni insaponati che ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  class\n",
       "398186  ma è altresì necessario non limitarsi alla dif...      0\n",
       "398187  ma è altrettanto importante ricordare in mazzo...      0\n",
       "398188  ma è anche abbastanza normale che lincumbent f...      0\n",
       "398189  ma è anche certo che quei personaggi non servo...      0\n",
       "398190  ma è anche come mille biscioni insaponati che ...      0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    11.101886\n",
       "class        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of words and mean\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    26\n",
       "class        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    4.147538\n",
       "class       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of the lengths\n",
    "%matplotlib inline\n",
    "\n",
    "length_sentence = dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1)\n",
    "plt.hist(length_sentence['sentence'],bins=range(50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dal punto di vista costruttivo le torri evapor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idem per le prestazioni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accetterei un forse ogni giorno della settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stessa storia della scorsa settimana uomo bian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dati auditel mondiali 2010 pane amore e privat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>il cespuglio è una forma di allevamento libera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lesplorazione della superficie e la bassa atmo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oggi parte la settimana dei test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dallincarico dopo la 31ª giornata a causa degl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>puoi aprire gli eventi nell'applicazione agenda ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0  dal punto di vista costruttivo le torri evapor...      0\n",
       "1                            idem per le prestazioni      0\n",
       "2    accetterei un forse ogni giorno della settimana      1\n",
       "3  stessa storia della scorsa settimana uomo bian...      1\n",
       "4  dati auditel mondiali 2010 pane amore e privat...      0\n",
       "5  il cespuglio è una forma di allevamento libera...      0\n",
       "6  lesplorazione della superficie e la bassa atmo...      0\n",
       "7                   oggi parte la settimana dei test      1\n",
       "8  dallincarico dopo la 31ª giornata a causa degl...      0\n",
       "9  puoi aprire gli eventi nell'applicazione agenda ?      1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index = [i for i in range(dataset_df.shape[0])]\n",
    "random.shuffle(index)\n",
    "dataset = dataset_df.set_index([index]).sort_index()\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('/home/asr/Data/classif_task/dev_data/dataset_blc.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dal punto di vista costruttivo le torri evapor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idem per le prestazioni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accetterei un forse ogni giorno della settimana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stessa storia della scorsa settimana uomo bian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dati auditel mondiali 2010 pane amore e privat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>il cespuglio è una forma di allevamento libera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lesplorazione della superficie e la bassa atmo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oggi parte la settimana dei test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dallincarico dopo la 31ª giornata a causa degl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>puoi aprire gli eventi nell applicazione agenda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>quello che e successo sabato sera e successo p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modifica l attività del prossimo mese sposta a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>avrebbe dato un breve sguardo al grosso volume...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>puoi condividere con fernanda tramite bluetoot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cannarozzo precedendo andrea camilleri santo p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>le ho dato una settimana di prova</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>crea appuntamento alle otto meno dieci di matt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple non ha mai prodotto né annunciato linten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fu socio corrispondente della r</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>puoi aggiungere un evento per favore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  class\n",
       "0   dal punto di vista costruttivo le torri evapor...      0\n",
       "1                             idem per le prestazioni      0\n",
       "2     accetterei un forse ogni giorno della settimana      1\n",
       "3   stessa storia della scorsa settimana uomo bian...      1\n",
       "4   dati auditel mondiali 2010 pane amore e privat...      0\n",
       "5   il cespuglio è una forma di allevamento libera...      0\n",
       "6   lesplorazione della superficie e la bassa atmo...      0\n",
       "7                    oggi parte la settimana dei test      1\n",
       "8   dallincarico dopo la 31ª giornata a causa degl...      0\n",
       "9     puoi aprire gli eventi nell applicazione agenda      1\n",
       "10  quello che e successo sabato sera e successo p...      1\n",
       "11  modifica l attività del prossimo mese sposta a...      1\n",
       "12  avrebbe dato un breve sguardo al grosso volume...      0\n",
       "13  puoi condividere con fernanda tramite bluetoot...      1\n",
       "14  cannarozzo precedendo andrea camilleri santo p...      0\n",
       "15                  le ho dato una settimana di prova      1\n",
       "16  crea appuntamento alle otto meno dieci di matt...      1\n",
       "17  apple non ha mai prodotto né annunciato linten...      0\n",
       "18                    fu socio corrispondente della r      0\n",
       "19               puoi aggiungere un evento per favore      1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude1 = ['\\t', '\"', '?'] # list\n",
    "exclude2 = [\"'\", \"  \", \"   \", \"    \", \"     \"] # list\n",
    "\n",
    "def clean_text(text):\n",
    "    for c in exclude1:\n",
    "        text=text.replace(c,'')\n",
    "    for c in exclude2:\n",
    "        text=text.replace(c, \" \")\n",
    "    return text.lower().strip()\n",
    "\n",
    "sentence_processed = list(map(lambda text: clean_text(text), dataset['sentence'].values))\n",
    "\n",
    "dataset['sentence'] = sentence_processed\n",
    "\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vorrei aggiungere appuntamento all agenda per ogni weekend\n",
      "larmistizio di vignale\n",
      "continuò fino alsalvo l interruzione della seconda guerra mondiale e fu progettata per un pubblico femminile borghese\n",
      "parte di itachi sasuke visse solo con lo scopo di vendicare la famiglia e uccidere il\n",
      "attribuzione errata\n",
      "identificare tutto il gruppo\n",
      "puoi creare un appuntamento alle cinque di mattina per favore\n",
      "solo si rifiuta ma gli darà la mano in segno di rispetto\n",
      "puoi creare un evento chiamato appuntamento con massimo alle sette e quarantacinque ogni primo weekend del mese\n",
      "cioe un vero appuntamento che non fosse con un paziente o suo figlio\n",
      "variabili superando talora anche i 300 metri\n",
      "a poppa due tramogge per bombe torpedini da getto da 50 e 100 kg e due\n",
      "poi piu tardi se ne andra e rimarremo solo io e te per l evento principale\n",
      "grandi edifici il museo de logroňo con collezioni di sculture e quadri di varie epoche e\n",
      "la membrana della maggior parte di questi batteri grampositivi è acido micolico con peptidoglicano il che\n",
      "cavolo stephanie e la peggiore organizzatrice di eventi della storia\n",
      "culinarie allaperto dove è possibile assaggiare sapori e piatti della tradizione locale dinverno invece lappuntamento immancabile\n",
      "c è una riunione d emergenza del consiglio di sicurezza a ginevra tra poche ore\n",
      "del genere umano\n",
      "gli archivi del consilgio noti come archivo general de indias sono ospitati a siviglia e dalfanno\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset.iloc[i]['sentence'])\n",
    "    print(dataset.iloc[-i -1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Set size: 338462\n",
      "Test-Set size: 59729\n"
     ]
    }
   ],
   "source": [
    "splitter = model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=19850610)\n",
    "\n",
    "splits = list(splitter.split(X=dataset['sentence'], y=dataset['class']))\n",
    "main_index = splits[0][0]\n",
    "test_index = splits[0][1]\n",
    "\n",
    "main_df = dataset.loc[main_index,:]\n",
    "print('Training-Set size: %d' %len(main_df))\n",
    "\n",
    "test_df = dataset.loc[test_index,:]\n",
    "print('Test-Set size: %d' %len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338462"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = main_df.dropna()\n",
    "len(main_df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59729"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.dropna()\n",
    "len(test_df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Set size: 71077\n",
      "Inference-Set size: 267385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asr/tensorflow-cpu/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "splitter =  model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.79, random_state=19850610)\n",
    "\n",
    "splits = list(splitter.split(X=main_df['sentence'], y=main_df['class']))\n",
    "train_index = splits[0][0]\n",
    "infer_index = splits[0][1]\n",
    "\n",
    "train_df = main_df.loc[train_index,:]\n",
    "print('Training-Set size: %d' %len(train_df))\n",
    "\n",
    "infer_df = main_df.loc[infer_index,:]\n",
    "print('Inference-Set size: %d' %len(infer_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60603"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.dropna()\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227162"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_df = infer_df.dropna()\n",
    "len(infer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "0.0    30441\n",
      "1.0    30162\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 50.23\n",
      "class 1 %: 49.77\n",
      "\n",
      "Test Set\n",
      "0    29919\n",
      "1    29810\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 50.09\n",
      "class 1 %: 49.91\n",
      "\n",
      "Inference Set\n",
      "0.0    113715\n",
      "1.0    113447\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 50.06\n",
      "class 1 %: 49.94\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "training_value_counts = train_df['class'].value_counts()\n",
    "print(training_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(training_value_counts[0]/len(train_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(training_value_counts[1]/len(train_df)*100,2)))\n",
    "print(\"\")\n",
    "print(\"Test Set\")\n",
    "validation_value_counts = test_df['class'].value_counts()\n",
    "print(validation_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(validation_value_counts[0]/len(test_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(validation_value_counts[1]/len(test_df)*100,2)))\n",
    "print(\"\")\n",
    "print(\"Inference Set\")\n",
    "inference_value_counts = infer_df['class'].value_counts()\n",
    "print(inference_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(inference_value_counts[0]/len(infer_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(inference_value_counts[1]/len(infer_df)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class'] = train_df['class'].apply(lambda x: str(int(x)))\n",
    "test_df['class'] = test_df['class'].apply(lambda x: str(int(x)))\n",
    "infer_df['class'] = infer_df['class'].apply(lambda x: str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(os.getcwd(), './dataset/train-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')\n",
    "test_df.to_csv(os.path.join(os.getcwd(), './dataset/test-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')\n",
    "infer_df.to_csv(os.path.join(os.getcwd(), './dataset/infer-data-maxlength16-subtitles.tsv'), header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = pd.read_csv(os.path.join(os.getcwd(), 'data-preparation/train-data-maxlength16-subtitles.tsv'), sep='\\t', names=['sentence','class'])\n",
    "#tt['sentence'].iloc[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Vocabulary and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('italian') + get_stop_words('english')\n",
    "\n",
    "my_stop_words = ['puoi','posso','vediamo','guarda','vorrei','voglio','dici','fammi']\n",
    "for my_word in my_stop_words:\n",
    "    stop_words.append(my_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criks', '16', '9']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = ['criks', 'crjis3','cr456is', '45crist','1v','f4','16','l','9','5ffff56566778','cv']\n",
    "\n",
    "falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "[w for w in ww if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function returns FALSE if there is a digit in the string (i.e '4mmm', 'm44m', 'llp4')\n",
    "falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "def get_vocab():\n",
    "    #allWords = []\n",
    "    vocab = set()\n",
    "    for text in train_df['sentence'].values:\n",
    "        text = str(text)\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]\n",
    "        #allWords = allWords + words_\n",
    "        word_set = set(words_)\n",
    "        vocab.update(word_set)\n",
    "    \n",
    "    #vocab.remove('')\n",
    "    return list(vocab)#, allWords\n",
    "\n",
    "def get_all_words():\n",
    "    allWords = []\n",
    "    cnt = 0\n",
    "    for text in train_df['sentence'].values:\n",
    "        text = str(text)\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 2 or w.isdigit()) ]\n",
    "        allWords = allWords + words_\n",
    "        #word_set = set(words_)\n",
    "        cnt += 1\n",
    "        if cnt%10000==0:\n",
    "            print('-----------', cnt)\n",
    "    \n",
    "    return allWords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59763\n",
      "CPU times: user 1.39 s, sys: 66 µs, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = get_vocab()\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 10000\n",
      "----------- 20000\n",
      "----------- 30000\n",
      "----------- 40000\n",
      "----------- 50000\n",
      "----------- 60000\n",
      "----------- 70000\n",
      "CPU times: user 5min 5s, sys: 151 ms, total: 5min 5s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allWords = get_all_words()\n",
    "len(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt_allWords = Counter(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence = sorted(cnt_allWords.items(), key=lambda kv: len(vocab) - kv[1])\n",
    "#vocab_words_sorted_by_appearence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence_list = [word[0] for word in vocab_words_sorted_by_appearence]\n",
    "#vocab_words_sorted_by_appearence_list, len(vocab_words_sorted_by_appearence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59453\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = True\n",
    "REDUCED_SIZE_VOC = True\n",
    "SIZE_VOC = 5000\n",
    "\n",
    "vocab = vocab_words_sorted_by_appearence_list\n",
    "\n",
    "if STOP_WORDS:\n",
    "    vocab = [w for w in vocab if w not in stop_words]\n",
    "    words_and_frequence = [ (word, freq) for (word, freq) in vocab_words_sorted_by_appearence if word not in stop_words]\n",
    "\n",
    "print(len(vocab))\n",
    "if REDUCED_SIZE_VOC:\n",
    "    vocab = vocab[0:SIZE_VOC]\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Mixed Vocabulary\n",
    "###### half of most frequent words, half of random selection among all the words (uniform distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['settimana',\n",
       " 'attività',\n",
       " 'favore',\n",
       " 'piacere',\n",
       " 'appuntamento',\n",
       " 'calendario',\n",
       " 'prossimo',\n",
       " 'evento',\n",
       " 'condividere',\n",
       " 'nome']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From 0 to boundary_point: words selected by their frequency (the most frequent words)\n",
    "# From boundary_point to len(voc): words random selected\n",
    "boundary_point = 19000\n",
    "\n",
    "def random_selection_from_vocab(vocabulary, start):\n",
    "    length_voc = len(vocabulary)\n",
    "    vocab = np.array(vocabulary)\n",
    "    indxs = np.random.choice(range(start, length_voc), length_voc - start, replace=False)\n",
    "    return list(vocab[indxs])\n",
    "\n",
    "vocab = vocab[0:boundary_point] + random_selection_from_vocab(vocab, boundary_point)\n",
    "vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_and_frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if a word is in VOC or STOP_WORDS\n",
    "ww = 'agenda'\n",
    "print(ww in stop_words)\n",
    "print(ww in vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_WORD = '#=KS=#'\n",
    "\n",
    "PATH_VOC = os.path.join(os.getcwd(), 'dataset/vocab_5k.tsv')\n",
    "with open(PATH_VOC , 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/vocab_list.tsv', 'w') as file:\n",
    "    file.write(\"{}\\n\".format(PAD_WORD))\n",
    "    for word in vocab:\n",
    "        file.write(\"{}\\n\".format(word))\n",
    "        \n",
    "PATH_WORDS = os.path.join(os.getcwd(), 'dataset/n_words_5k.tsv')        \n",
    "with open(PATH_WORDS, 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/n_words.tsv', 'w') as file:\n",
    "    file.write(str(len(vocab)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
